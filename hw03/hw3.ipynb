{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx0EFrNbvg1W"
      },
      "source": [
        "# Домашнее задание 3. VAE + NF + VAPNEV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ75HjhTvg1b"
      },
      "source": [
        "### Загрузка данных\n",
        "В данном задании вам предстоит снова работать с CelebA\n",
        "\n",
        "Решением домашки является архив с использованными тетрадками/модулями, а так же .pdf файл с отчетом по проделанной работе по каждому пункту задачи. В нем необходимо описать какие эксперименты вы производили чтобы получить результат который вы получили, а так же обосновать почему вы решили использовать штуки которые вы использовали (например, дополнительные лоссы для стабилизации, разные виды потоков, разные хаки для вае)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrw0cRBGYm1j"
      },
      "outputs": [],
      "source": [
        "%pip install numba\n",
        "%pip install pytorch-fid-wrapper\n",
        "%pip install wandb\n",
        "%pip install -U --no-cache-dir gdown --pre\n",
        "!git clone https://github.com/HSE-LAMBDA/DeepGenerativeModels.git\n",
        "!gdown --id 17lt5GBYn17jMXbP1riwpbrW0byY2UY70\n",
        "# import gdown\n",
        "# gdown.download(id=\"17lt5GBYn17jMXbP1riwpbrW0byY2UY70\", quiet=False)\n",
        "!unzip -q img_align_celeba.zip* \n",
        "!curl https://raw.githubusercontent.com/taki0112/StarGAN-Tensorflow/master/dataset/celebA/list_attr_celeba.txt 2> /dev/null | tail +2 > list_attr_celeba.txt\n",
        "!cat list_attr_celeba.txt > img_align_celeba/list_attr_celeba.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFluhS9ZRa-j"
      },
      "outputs": [],
      "source": [
        "!wandb login "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yZNEX7fvg1e"
      },
      "outputs": [],
      "source": [
        "from DeepGenerativeModels.utils.datasets.celeba import CelebADataset\n",
        "from datetime import datetime\n",
        "from matplotlib import rcParams\n",
        "import pytorch_fid_wrapper as pfw\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torchvision import transforms\n",
        "from torchvision.models import inception_v3\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import trange, tqdm\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import wandb\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = (20, 10)\n",
        "cwd = os.getcwd()\n",
        "torch.manual_seed(142)\n",
        "np.random.seed(142)"
      ],
      "metadata": {
        "id": "7eAiW0APizlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kczpWSXIvg1h"
      },
      "outputs": [],
      "source": [
        "t_normalize = lambda x: x * 2 - 1\n",
        "t_invnormalize = lambda x: (x + 1) / 2\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomApply([transforms.functional.hflip]),\n",
        "    transforms.Lambda(t_normalize),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-tDHG6G5qwx"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufX-jWjm5ZX0"
      },
      "outputs": [],
      "source": [
        "dataset = CelebADataset(root_dir=cwd, transform=transform)\n",
        "\n",
        "num_workers = 0 if device.type == \"cuda\" else 2\n",
        "\n",
        "pin_memory = True if device.type == \"cuda\" else False\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=16,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_grid_np(images, nrow=8):\n",
        "    return make_grid(\n",
        "        [t_invnormalize(img) for img in images],\n",
        "        pad_value=1,\n",
        "        padding=3,\n",
        "        nrow=nrow\n",
        "    ).permute(1, 2, 0).numpy()\n",
        "\n",
        "def show_images(images, title=None, nrow=8):\n",
        "    plt.imshow(make_grid_np(images,nrow=nrow))\n",
        "    plt.axis(\"off\")\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5ydacJK2wIis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjban2MAvg1k"
      },
      "source": [
        "### Визуализация датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na-5flx3a8hk"
      },
      "outputs": [],
      "source": [
        "show_images([dataset[np.random.randint(len(dataset))][0] for i in range(32)], nrow=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So3ZCZMlvg1m"
      },
      "source": [
        "### Задача 1 (4/10 балла). Построить и обучить нормпоток на CelebA\n",
        "\n",
        "Здесь нужно обучить нормпоток до нормального (трешхолды будут позже) качества, померить FID и Negative Log Likelihood и запомнить для будущего сравнения\n",
        "\n",
        "Внутри потока можно использовать все что вы хотите, Coupling/Autoregressive/Linear слои, любые трансформации и все что вам приходит в голову. Но все что вы используете - напишите сами, без копипаста.\n",
        "\n",
        "Можно использовать как и сверточные потоки (будут лучше, но сложнее писать), так и линейные (будут хуже), развернув селебу в один вектор.\n",
        "\n",
        "В принципе можно использовать тот код который уже есть в репозитории курса, но лучше написать свой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7QkKuqmXAqq"
      },
      "source": [
        "### Задача 2 (2/10 балла). Построить и обучить VAE на CelebA\n",
        "\n",
        "Здесь нужно обучить VAE до нормального качества, померить FID и запомнить для будущего сравнения. \n",
        "\n",
        "В принципе можно использовать тот код который уже есть в репозитории курса, но лучше написать свой\n",
        "\n",
        "Ради интереса, ваше вае тоже можно потестировать на маленьких датасетах\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TedN10Nvb-rL"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, img_size=64, latent_size=512, start_channels=16, downsamplings=5):\n",
        "        super().__init__()\n",
        "        blocks = [nn.Conv2d(in_channels=3, out_channels=start_channels, kernel_size=1, stride=1, padding=0)]\n",
        "        in_channels = start_channels\n",
        "        for i in range(downsamplings):\n",
        "            blocks += [\n",
        "                nn.Conv2d(in_channels=in_channels, out_channels=in_channels * 2, kernel_size=3, stride=2, padding=1),\n",
        "                nn.BatchNorm2d(in_channels * 2),\n",
        "                nn.LeakyReLU()\n",
        "            ]\n",
        "            in_channels *= 2\n",
        "            img_size //= 2\n",
        "        blocks += [\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=in_channels * img_size ** 2, out_features=2 * latent_size)\n",
        "        ]\n",
        "        self.network = nn.Sequential(*blocks)\n",
        "        self.N = torch.distributions.Normal(0, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.network(x)\n",
        "        mu, sigma = x.split(x.size(1) // 2, dim=1)\n",
        "        sigma = torch.exp(sigma)\n",
        "        return mu + sigma * self.N.sample(mu.shape).to(device), (mu, sigma)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, img_size=64, latent_size=512, end_channels=16, upsamplings=5):\n",
        "        super().__init__()\n",
        "        in_channels = end_channels * (2 ** upsamplings)\n",
        "        img_size //= 2 ** upsamplings\n",
        "        blocks = [\n",
        "            nn.Linear(in_features=latent_size, out_features=in_channels * img_size ** 2),\n",
        "            nn.Unflatten(1, (in_channels, img_size, img_size)),\n",
        "        ]\n",
        "        for i in range(upsamplings):\n",
        "            blocks += [\n",
        "                nn.ConvTranspose2d(in_channels=in_channels, out_channels=in_channels // 2, kernel_size=4, stride=2,\n",
        "                                   padding=1),\n",
        "                nn.BatchNorm2d(in_channels // 2),\n",
        "                nn.LeakyReLU()\n",
        "            ]\n",
        "            in_channels //= 2\n",
        "            img_size *= 2\n",
        "        blocks.append(nn.Conv2d(in_channels=in_channels, out_channels=3, kernel_size=1, stride=1, padding=0))\n",
        "        blocks.append(nn.Tanh())\n",
        "        self.network = nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.network(z)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, img_size=64, downsamplings=3, latent_size=120, down_channels=6, up_channels=9):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(img_size, latent_size, down_channels, downsamplings)\n",
        "        self.decoder = Decoder(img_size, latent_size, up_channels, downsamplings)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (mu, sigma) = self.encoder(x)\n",
        "        kld = 0.5 * (sigma ** 2 + mu ** 2 - 2 * torch.log(sigma + 1e-9) - 1)\n",
        "        x = self.decoder(x)\n",
        "        return x, kld\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)[0]\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def save(self, name=\"model.pth\"):\n",
        "        torch.save(self.state_dict(), name)\n",
        "\n",
        "    def load(self, name=None):\n",
        "        self.load_state_dict(torch.load(name if name is not None else (__file__[:-7] + \"model.pth\")))\n",
        "        self.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_vae_fid_score(dataloader, model, batches=100):\n",
        "    with torch.no_grad():\n",
        "        real_img = []\n",
        "        fake_img = []\n",
        "        for i, (batch, meta) in tqdm(enumerate(dataloader), total=batches):\n",
        "            if i == batches:\n",
        "                break\n",
        "            real_img.extend(batch)\n",
        "            fake_img.extend(vae.decoder(torch.randn_like(vae.encode(torch.zeros(dataloader.batch_size, 3, 64, 64).to(device)))))\n",
        "        return pfw.fid(torch.stack(real_img).to(device), torch.stack(fake_img).to(device), device=device)"
      ],
      "metadata": {
        "id": "VTZ76Oj7jaOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"generative-models-vae\",\n",
        "\n",
        "    config={\n",
        "        \"kl_factor\": 5,\n",
        "        \"architecture\": \"VAE\",\n",
        "        \"dataset\": \"CelebA\",\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 16,\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"learning_rate\": 0.001\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "7jiNpyoKImAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE().to(device)"
      ],
      "metadata": {
        "id": "fMIXvumx8pAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGxQOmb_WlnP"
      },
      "outputs": [],
      "source": [
        "batch_size = wandb.config[\"batch_size\"]\n",
        "vae_optim = torch.optim.Adam(vae.parameters(), 0.001)\n",
        "\n",
        "\n",
        "total_batch_id = 0\n",
        "for epoch in range(wandb.config[\"epochs\"]):\n",
        "    total_batches = 0\n",
        "    rec_loss_avg = 0\n",
        "    kld_loss_avg = 0\n",
        "    total_loss_avg = 0\n",
        "\n",
        "    for i, batch in tqdm(enumerate(dataloader), total=(len(dataset) + batch_size) // batch_size):\n",
        "        if i % 1000 == 0:\n",
        "            with torch.no_grad():\n",
        "                generated_file = f'generated{total_batch_id}.png'\n",
        "\n",
        "                plt.imsave(generated_file, make_grid_np(vae.decoder(torch.randn_like(vae.encode(torch.zeros(32, 3, 64, 64).to(device)))).cpu()))\n",
        "\n",
        "                artifact = wandb.Artifact('generated_image.png', type='image')\n",
        "                artifact.add_file(generated_file)\n",
        "                wandb.log_artifact(artifact)\n",
        "\n",
        "\n",
        "                interpolated_file = f'generated{total_batch_id}.png'\n",
        "\n",
        "                test_imgs_1 = torch.cat([dataset[i][0].unsqueeze(0) for i in (31, 34, 736, 1520, 34, 190, 42, 178)])\n",
        "                test_imgs_2 = torch.cat([dataset[i][0].unsqueeze(0) for i in (731, 132, 51, 32, 98, 67, 127, 79)])\n",
        "                z_1 = vae.encode(test_imgs_1.to(device))\n",
        "                z_2 = vae.encode(test_imgs_2.to(device))\n",
        "                x_int = []\n",
        "                for i in range(9):\n",
        "                    z = (i * z_1 + (8 - i) * z_2) / 8\n",
        "                    x_int.append(vae.decode(z))\n",
        "                x_int = torch.cat(x_int).cpu()\n",
        "                plt.imsave(interpolated_file, make_grid_np([x_int[j*8+i] for i in range(8) for j in range(9)], nrow=9))\n",
        "\n",
        "                artifact = wandb.Artifact('interpolated_image.png', type='image')\n",
        "                artifact.add_file(interpolated_file)\n",
        "                wandb.log_artifact(artifact)\n",
        "\n",
        "\n",
        "        if (total_batch_id % 2000 == 0):\n",
        "            model_file = f'model_{total_batch_id}.pth'\n",
        "            vae.save(model_file)\n",
        "            artifact = wandb.Artifact('model_weights', type='model')\n",
        "            artifact.add_file(model_file)\n",
        "            wandb.log_artifact(artifact)\n",
        "            \n",
        "            wandb.log({'fid': calculate_vae_fid_score(dataloader, vae, 100)}, step=total_batch_id)\n",
        "\n",
        "        batch = batch[0]\n",
        "        if len(batch) < batch_size:\n",
        "            continue\n",
        "        total_batches += 1\n",
        "        x = batch.to(device)\n",
        "        x_rec, kld = vae(x)\n",
        "        img_elems = float(np.prod(list(batch.size())))\n",
        "        kld_loss = kld.sum() / batch_size\n",
        "        rec_loss = ((x_rec - x)**2).sum() / batch_size\n",
        "        loss = rec_loss + wandb.config[\"kl_factor\"] * kld_loss \n",
        "        vae_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        vae_optim.step()\n",
        "        kld_loss_avg += kld_loss.item()\n",
        "        rec_loss_avg += rec_loss.item()\n",
        "        total_loss_avg += loss.item()\n",
        "\n",
        "        wandb.log({'kld_loss': kld_loss.item(), 'reconstruction_loss': rec_loss.item(), 'total_loss': loss.item()}, step=total_batch_id)\n",
        "        total_batch_id += 1\n",
        "        if i % 1000 == 0:\n",
        "            print(rec_loss_avg / total_batches, kld_loss_avg / total_batches, total_loss_avg / total_batches)\n",
        "\n",
        "\n",
        "    rec_loss, kld_loss = rec_loss_avg / total_batches, kld_loss_avg / total_batches\n",
        "    wandb.log({'kld_loss_epoch': kld_loss, 'reconstruction_loss_epoch': rec_loss}, step=epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ссылка на запуск в WandB: https://wandb.ai/debnatkh/generative-models-vae/runs/xm2cpe8c?workspace=user-debnatkh\n",
        "\n",
        "FID: 93.66\n",
        "\n",
        "Пример сгенерированной картинки:\n",
        "\n",
        "![image.png](https://storage.googleapis.com/wandb-artifacts-prod/wandb_artifacts/56528774/393045797/2c7605c8f9c8a11025a7fcef084bc8e4?Expires=1678466558&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=LZwokmzDWTK5eu7r1CVMRiFypmAIFAODGL6jeC2p08bQsPJiJgQWMKvxepF0D1zxgr7yb6qFsYpZGJQmiUecPts5AAHLVG0susUEyeVfAaRpGb3v4msTHW8tSUHsY%2FSdoI%2B1okSkPXodJ%2FPOoc%2BEgSP7eQ7gNrmKm5VdmijwVjs6pc5iLa%2FYCub73uZCu60OUl2PNmpnMgYLl2oRZztF7e0NOrPefUpOn4Ji0wiAkcSR%2BiZx4gsISFgerr1txUTu1KUZmfvUOjAt3BZI3uQqzFrNH51avmT8M3Jdwm37X08xyRJkxugb%2BXkIcXup0MnT3JuqP1ht61dT6BmHBQoWqg%3D%3D)\n",
        "\n",
        "Линейная интерполяция между двумя точками датасета:\n",
        "\n",
        "![image.png](https://storage.googleapis.com/wandb-artifacts-prod/wandb_artifacts/56528777/393045808/aac09c0cd73d302e089ab0c2a4425b92?Expires=1678466809&GoogleAccessId=wandb-production%40appspot.gserviceaccount.com&Signature=OqVo2WpXdihbGRUoih%2ByGPDv7za5DS4x8Ww7Q25BZfOsI6PPX9xpwdiiZAqfhNGa1%2B6nWtczCb988DwleDU5Px%2FWQxX%2FFk8T%2FJARKhv34A90rXfJd0OBQhR76%2FjYz9Vji%2B%2FOCLdqcE87DvJYEttv9fowLzJi%2BZ3d8P8HL%2BUkD5vCk6%2Ffsx9dZhdrstN5wt5iEBBOR8cYNZWo5q32Wb1DoVFdpKA3%2BkMhZjq8FdHobJGBxGrciJ2W2SnQT9xB%2BjuYhfL7nNnfT0pO8hdjydtDwTF9jkpLVDuXvjaxGUtfX5iXQaCnZK59%2BuUnsmiGKsNyXMAfzZIPpd8j%2F7wbn9oetw%3D%3D)\n",
        "\n",
        "\n",
        "Больше примеров в отчёте"
      ],
      "metadata": {
        "id": "qycGnMr4YMdT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyAv8tLMaB16"
      },
      "source": [
        "### Задача 3 (6/10 балла). \n",
        "\n",
        "#### Задача 3.1 (4/10 балла) Построить и обучить VAPNEV на CelebA\n",
        "\n",
        "Здесь нужно прочитать [статью про VAPNEV](https://arxiv.org/pdf/1611.05209.pdf), обучить его до нормального (трешхолды будут позже) качества, померить FID и запомнить для будущего сравнения. \n",
        "\n",
        "#### Задача 3.2 (2/10 балла). Построить и обучить conditional VAPNEV на CelebA\n",
        "\n",
        "Вроде понятно из текста задачи. Что такое conditional VAPNEV, читайте в статье"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id6meBQgWlqo"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aarIVpYFtuOh"
      },
      "source": [
        "### Задача 4. (1/10 балла) Анализ\n",
        "\n",
        "* Анализ латентного пространства и визуально качественный результат - **1 балл**\n",
        "1. Посмотрите у какой модели получается лучшая интерполяция в латентном пространстве\n",
        "2. Попробуйте взять внешнюю картинку (не из селебы), отмапить ее с латентное пространство и покажите ближайшие к ней.\n",
        "3. Покажите самый смешной результат генерации который у вас получался"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jndw28PsdUI8"
      },
      "outputs": [],
      "source": [
        "vae = VAE().to(device)\n",
        "# Последняя версия модели из WandB\n",
        "vae.load(\"/content/1080ccad73ee5736290b4ee183f6a2ef\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for scale in [0.2, 0.3, 0.5, 0.7, 0.9, 1, 1.2, 2]:\n",
        "        show_images(vae.decoder(scale * torch.randn_like(vae.encode(torch.zeros(32, 3, 64, 64).to(device)))).cpu(), title=f'Scale = {scale}')"
      ],
      "metadata": {
        "id": "kqzP9U9XzmrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    show_images(vae.decoder(torch.zeros_like(vae.encode(torch.zeros(1, 3, 64, 64).to(device)))).cpu(), title=f'Default person')"
      ],
      "metadata": {
        "id": "xsrD46rw7bwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "fSYB7jmY8Ugm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "me = transform(Image.open('/content/IMG_3172.png'))\n",
        "show_images([me], title='eto ya')"
      ],
      "metadata": {
        "id": "IxEpgeGJ8e_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    target = vae.encode(me.unsqueeze(0).to(device))[0].detach()\n",
        "\n",
        "closest = (1e9, None)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "for i, (batch, attr) in tqdm(enumerate(dataloader), total=(len(dataset) + batch_size) // batch_size):\n",
        "    with torch.no_grad():\n",
        "        candidates = vae.encode(batch.to(device))\n",
        "        distances = torch.cdist(candidates, target.view(1, -1))\n",
        "\n",
        "        min_index = torch.argmin(distances)\n",
        "\n",
        "        closest = min(closest, (distances[min_index], batch[min_index].clone().detach()))\n",
        "\n",
        "show_images([closest[-1]])"
      ],
      "metadata": {
        "id": "GXNjB-SK8qOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yqAp6xv--bmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sokolov = transform(Image.open('/content/sokolov.jpg'))\n",
        "show_images([sokolov])"
      ],
      "metadata": {
        "id": "JtbR5JGjAmdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    target = vae.encode(sokolov.unsqueeze(0).to(device))[0].detach()\n",
        "\n",
        "closest = (1e9, None)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "for i, (batch, attr) in tqdm(enumerate(dataloader), total=(len(dataset) + batch_size) // batch_size):\n",
        "    with torch.no_grad():\n",
        "        candidates = vae.encode(batch.to(device))\n",
        "        distances = torch.cdist(candidates, target.view(1, -1))\n",
        "\n",
        "        min_index = torch.argmin(distances)\n",
        "\n",
        "        closest = min(closest, (distances[min_index], batch[min_index].clone().detach()))\n",
        "\n",
        "show_images([closest[-1]])"
      ],
      "metadata": {
        "id": "rUmIXZJrCBZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onwr5mI9dTgf"
      },
      "source": [
        "### Задача 0. Отчет\n",
        "\n",
        "Чтобы получить полный балл за каждый из пунктов вам нужно включить в отчет (который сдатеся отдельно в виде pdf) примеры (лучше - много примеров) генерации вашей модели. \n",
        "\n",
        "Сравните результаты разных моделей, попробуйте обьяснить почему одна сработала лучше чем другая."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отчёт прикрепил в отправку + загрущил на диск:\n",
        "https://disk.yandex.ru/i/27nMc_a1kk6GPA"
      ],
      "metadata": {
        "id": "sNs81xjgJpfY"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "notebookId": "0cd94a29-c140-4980-83be-c24d84b0c2ad",
    "notebookPath": "hw3_vapnev.ipynb",
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}